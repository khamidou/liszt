#!/usr/bin/env python
# This is the daemon that actually does the network operations.
# This is how it works : the ui program (liszt) creates json files corresponding to requests in the ~/.liszt/delayed directory.
# The daemon periodically scans this folder to sends the requests to the server.
# The format of a request file is :
#
# {"request": request-type, "listname" : ___, "content" : {"title" : ___, "done" : ___, "date" : ___ }}
# with request-type being : 	"create-entry", "update-entry", "delete-entry",
#				"create-list", "update-list", "delete-list".


import sys
import os
import sets
from datetime import datetime
import threading
import time
import ConfigParser

from libliszt.utils import Daemon, LisztSession, CachedList, sorted_dirlist


try:
    import json 
except ImportError:
    import simplejson as json                                                                                                                         


conf = ConfigParser.RawConfigParser()
conf.read(os.path.expanduser('~/.liszt/config'))
username = conf.get('Credentials', 'username')
password = conf.get('Credentials', 'password')

session = LisztSession()
session.login(username, password)


update_interval = 10 * 60 # Please be nice on the server - A ten minutes interval should be good enough.

def process_json_delayed_file(path, session):
    try:
        fd = open(path)
    except IOError:
        return

    data = json.load(fd)

    if "request" not in data or "listname" not in data:
        return # Discard incorrect files

    if data["request"] == "create-list":
        session.create_list(data["listname"])
    elif data["request"] == "create-entry":
        try:
            session.create_list_entry(data["listname"], data["contents"]["title"]) 	# FIXME : use the other options if defined.
        except KeyError:
            return

    elif data["request"] == "delete-list":
        session.remove_list(data["listname"])
    elif data["request"] == "delete-entry":
        try:
            session.remove_list_entry(data["listname"], data["contents"]["index"])
        except KeyError:
            return
    elif data["request"] == "update-entry":
        try:
            session.update_list_entry(data["listname"], data["contents"]["index"], data["content"])
        except KeyError:
            return
        
    os.unlink(path)

def watch_spool_dir():
    while True:
        for file in sorted_dirlist(os.path.expanduser('~/.liszt/delayed/')):
            process_json_delayed_file(os.path.expanduser('~/.liszt/delayed/') + file, session)

        
        time.sleep(update_interval) # Sync the files with the server every 15 minutes.

def cache_new_lists():
    # This thread caches lists that were recently created on the server but are not available
    # on the client.
    
    while True:
        server_set = set(session.get_lists_list())
        cached_set = set(os.listdir(os.path.expanduser('~/.liszt/cached/')))
    
        for not_cached_list in server_set.difference(cached_set):
            l = CachedList(not_cached_list)
            l.contents = session.get_list(not_cached_list)
            l.save()

    	# Also save a list of the lists :
        cl = CachedList('lists_list')
        l = set(session.get_lists_list())
        cl.contents = l.union(cl.contents)
        cl.contents = list(cl.contents)
        cl.save()

        time.sleep(update_interval)
        
def sync_cached_list(listname):
    def isentrydefined(title, l):
        # Is an entry in a list ? Yes if it's title is in the list
        for e in l:
            if e["title"] == title:
                return True

        return False

    cached_list = CachedList(listname)
    server_list = session.get_list(listname)

    print server_list
    for entry in server_list:

        if isinstance(entry, list): # Discard lists for the moment
            continue
        
        cached_list.contents[entry] = server_list[entry]

    for entry in server_list["contents"]:
        if not isentrydefined(entry["title"], cached_list.contents["contents"]):
            cached_list.contents["contents"].push(entry)

    cached_list.save()
    
def watch_cache_dir():
    while True:
        for cached_list in os.listdir(os.path.expanduser('~/.liszt/cached/')):
            if cached_list == "lists_list":
                continue
            sync_cached_list(cached_list)

        time.sleep(update_interval)

class SpoolThread(threading.Thread):
    def run(self):
        watch_spool_dir()

class CacheNewListsThread(threading.Thread):
    def run(self):
        cache_new_lists()

class SyncListsThread(threading.Thread):
    def run(self):
        watch_cache_dir()

class LisztDaemon(Daemon):
    def run(self):
         st = SpoolThread()
         st.start()

         clt = CacheNewListsThread()
         clt.start()

         slt = SyncListsThread()
         slt.start()


if __name__ == "__main__":
   daemon = LisztDaemon(pidfile="/var/lock/liszt-daemon.pidfile")
   daemon.run()
#   daemon.start()
