#!/usr/bin/env python
# This is the daemon that actually does the network operations.
# This is how it works : the ui program (liszt) creates json files corresponding to requests in the ~/.liszt/delayed directory.
# The daemon periodically scans this folder to sends the requests to the server.
# The format of a request file is :
#
# {"request": request-type, "listname" : ___, "content" : {"title" : ___, "done" : ___, "date" : ___ }}
# with request-type being : 	"create-entry", "update-entry", "delete-entry",
#				"create-list", "update-list", "delete-list".


import sys
import os
import sets
from datetime import datetime
import thread
import time
import ConfigParser

from libliszt.utils import Daemon, LisztSession


try:
    import json 
except ImportError:
    import simplejson as json                                                                                                                         


conf = ConfigParser.RawConfigParser()
conf.read(os.path.expanduser('~/.liszt/config'))
username = conf.get('Credentials', 'username')
password = conf.get('Credentials', 'password')

def process_json_delayed_file(path):
    try:
        fd = open(path)
    except IOError:
        return

    data = json.load(fd)

    if "request" not in data or "listname" not in data:
        return # Discard incorrect files

    if data["request"] == "create-list":
        session.create_list(data["listname"])
    elif data["request"] == "create-entry":
        try:
            session.create_list_entry(data["listname"], data["content"]["title"]) 	# FIXME : use the other options if defined.
        except KeyError:
            return

    elif data["request"] == "delete-list":
        session.remove_list(data["listname"])
    elif data["request"] == "delete-entry":
        try:
            session.remove_list_entry(data["listname"], data["content"]["index"])
        except KeyError:
            return
    elif data["request"] == "update-entry":
        try:
            session.update_list_entry(data["listname"], data["content"]["index"], data["content"])
        except KeyError:
            return
        
    os.unlink(path)

def watch_spool_dir():
    while True:
        for file in os.listdir(os.path.expanduser('~/.liszt/delayed/')):
            process_json_delayed_file(os.path.expanduser('~/.liszt/delayed/') + file)

        time.sleep(15 * 60) # Sync the files with the server every 15 minutes.

def cache_lists_list():
#     l = set(session.get_lists_list())
#     fd = open(os.path.expanduser('~/.liszt/cached/'), 'w+')
#     json.dump(l, fd)
#     fd.close()
    pass

def cache_new_lists():
    # This thread caches lists that were recently created on the server but are not available
    # on the client.

    server_set = set(session.get_lists_list())
    cached_set = set(os.listdir(os.path.expanduser('~/.liszt/cached/')))
    
    for list in server_set.difference(cached_set):
        try:
            fd = open(os.path.expanduser('~/.liszt/cached/') + list, 'w+')
        except IOError:
            continue

        dict = session.get_list(list)
        json.dump(dict, fd)
        fd.close()

    # Also save a list of the lists :
    fd = open(os.path.expanduser('~/.liszt/cached/lists_list'), 'w+')
    json.dump(session.get_lists_list(), fd)
    fd.close()

    time.sleep(15 * 60)
        
def sync_cached_list(path):
    def isentrydefined(title, list):
        # Is an entry in a list ? Yes if it's title is in the list
        for e in list:
            if e["title"] == title:
                return True

        return False

    try:
        fd = open(path)
    except IOError:
        return

    cached_list = json.load(fd)
    try:
        listname = cached_list["name"]
    except KeyError:
        return

    server_list = session.get_list(listname)

    for entry in server_list:
        if isinstance(entry, list): # Discard lists for the moment
            continue
        
        cached_list[entry] = server_list[entry]

    for entry in server_list["contents"]:
        if not isentrydefined(entry["title"], cached_list["contents"]):
            cached_list["contents"].push(entry)

    json.dump(fd)
    
def watch_cache_dir(name, session):
    while True:
        for file in os.listdir(os.path.expanduser('~/.liszt/cached/')):
            sync_cached_list(os.path.expanduser('~/.liszt/cached/') + file)
        
        time.sleep(20 * 60) # Sync the files with the server every 20 minutes.

# class LisztDaemon(Daemon):
#     def run(self):
#         pass

if __name__ == "__main__":
    session = LisztSession()
    session.login(username, password)
    
    thread.start_new_thread(watch_spool_dir, ())
    thread.start_new_thread(cache_new_lists, ())
#    daemon = LisztDaemon(pidfile="/var/lock/liszt-daemon.pidfile")

