#!/usr/bin/env python
# This is the daemon that actually does the network operations.
# This is how it works : the ui program (liszt) creates json files corresponding to requests in the ~/.liszt/delayed directory.
# The daemon periodically scans this folder to sends the requests to the server.
# The format of a request file is :
#
# {"request": request-type, "listname" : ___, "content" : {"title" : ___, "done" : ___, "date" : ___ }}
# with request-type being : 	"create-entry", "update-entry", "delete-entry",
#				"create-list", "update-list", "delete-list".


import sys
import os
import sets
from datetime import datetime
import urllib, urllib2, cookielib
from urllib import quote
from urllib2 import HTTPError, URLError
import subprocess
from subprocess import Popen
import fnmatch
import tempfile
import thread
import time
import ConfigParser
import atexit
from signal import SIGTERM 

try:
    import json 
except ImportError:
    import simplejson as json                                                                                                                         


base = "http://0.0.0.0:8080/api/v1"

conf = ConfigParser.RawConfigParser()
conf.read(os.path.expanduser('~/.liszt/config'))
username = conf.get('Credentials', 'username')
password = conf.get('Credentials', 'password')


# The Daemon class comes from http://www.jejik.com/articles/2007/02/a_simple_unix_linux_daemon_in_python/
class Daemon:
	"""
	A generic daemon class.
	
	Usage: subclass the Daemon class and override the run() method
	"""
	def __init__(self, pidfile, stdin='/dev/null', stdout='/dev/null', stderr='/dev/null'):
		self.stdin = stdin
		self.stdout = stdout
		self.stderr = stderr
		self.pidfile = pidfile
	
	def daemonize(self):
		"""
		do the UNIX double-fork magic, see Stevens' "Advanced 
		Programming in the UNIX Environment" for details (ISBN 0201563177)
		http://www.erlenstar.demon.co.uk/unix/faq_2.html#SEC16
		"""
		try: 
			pid = os.fork() 
			if pid > 0:
				# exit first parent
				sys.exit(0) 
		except OSError, e: 
			sys.stderr.write("fork #1 failed: %d (%s)\n" % (e.errno, e.strerror))
			sys.exit(1)
	
		# do second fork
		try: 
			pid = os.fork() 
			if pid > 0:
				# exit from second parent
				sys.exit(0) 
		except OSError, e: 
			sys.stderr.write("fork #2 failed: %d (%s)\n" % (e.errno, e.strerror))
			sys.exit(1) 
	
		# redirect standard file descriptors
		sys.stdout.flush()
		sys.stderr.flush()
		si = file(self.stdin, 'r')
		so = file(self.stdout, 'a+')
		se = file(self.stderr, 'a+', 0)
		os.dup2(si.fileno(), sys.stdin.fileno())
		os.dup2(so.fileno(), sys.stdout.fileno())
		os.dup2(se.fileno(), sys.stderr.fileno())
	
		# write pidfile
		atexit.register(self.delpid)
		pid = str(os.getpid())
		file(self.pidfile,'w+').write("%s\n" % pid)
	
	def delpid(self):
		os.remove(self.pidfile)

	def start(self):
		"""
		Start the daemon
		"""
		# Check for a pidfile to see if the daemon already runs
		try:
			pf = file(self.pidfile,'r')
			pid = int(pf.read().strip())
			pf.close()
		except IOError:
			pid = None
	
		if pid:
			message = "pidfile %s already exist. Daemon already running?\n"
			sys.stderr.write(message % self.pidfile)
			sys.exit(1)
		
		# Start the daemon
		self.daemonize()
		self.run()

	def stop(self):
		"""
		Stop the daemon
		"""
		# Get the pid from the pidfile
		try:
			pf = file(self.pidfile,'r')
			pid = int(pf.read().strip())
			pf.close()
		except IOError:
			pid = None
	
		if not pid:
			message = "pidfile %s does not exist. Daemon not running?\n"
			sys.stderr.write(message % self.pidfile)
			return # not an error in a restart

		# Try killing the daemon process	
		try:
			while 1:
				os.kill(pid, SIGTERM)
				time.sleep(0.1)
		except OSError, err:
			err = str(err)
			if err.find("No such process") > 0:
				if os.path.exists(self.pidfile):
					os.remove(self.pidfile)
			else:
				print str(err)
				sys.exit(1)

	def restart(self):
		"""
		Restart the daemon
		"""
		self.stop()
		self.start()

	def run(self):
		"""
		You should override this method when you subclass Daemon. It will be called after the process has been
		daemonized by start() or restart().
		"""


class LisztSession:
    def __init__(self):

        self.jar = cookielib.LWPCookieJar()
        if os.path.isfile(os.path.expanduser('~/.liszt/cookiejar')):
            self.jar.load(os.path.expanduser('~/.liszt/cookiejar'))

        self.opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(self.jar))
        urllib2.install_opener(self.opener)

    def login(self, username, password):
        d = {'username' : username, 'password': password}
        ed = urllib.urlencode(d)
        
        while True:
            try:
                urllib2.urlopen(base + "/login/", ed)
                return
            except URLError, HTTPError:
                print "Unable to log you in"
                time.sleep(5 * 60) # Try to reconnect every five minutes.
                continue

    def create_list(self, listname):
        listname = listname.encode("utf8")
        try:
            urllib2.urlopen(base + "/create/" + quote(listname) + "/")
        except HTTPError:
            bailout("Unable to create the list " + listname)

    def create_list_entry(self, listname, entry):
        listname = listname.encode("utf8")
        entry = entry.encode("utf8")

        try:
            urllib2.urlopen(base + "/create/" + quote(listname) + "/" + quote(entry) + "/")
        except HTTPError:
            bailout("Unable to create the list entry in list " + listname)

    def get_lists_list(self):
        try:
            req = urllib2.urlopen(base + "/getlists/")
        except HTTPError:
            bailout("Unable to get a list of the available lists")
            
        return json.load(req)

    def get_list(self, listname):
        ln = self.glob_listname(listname)

        try:
            req = urllib2.urlopen(base + "/get/" + quote(ln) + "/")
        except HTTPError:
            bailout("Unable to open the list " + listname)

        return json.load(req)

    def get_entry(self, listname, index):
        ln = self.glob_listname(listname)

        try:
            req = urllib2.urlopen(base + "/get/" + quote(ln) + "/" + str(index) + "/")
        except HTTPError:
            bailout("Unable to get entry " + str(index) + " from list " + listname)

        return json.load(req)

    def remove_list(self, listname):
        try:
            urllib2.urlopen(base + "/remove/" + quote(listname) + "/")
        except HTTPError:
            bailout("Unable to remove the list " + listname)

    def remove_list_entry(self, listname, index):
        try:
            urllib2.urlopen(base + "/remove/" + quote(listname) + "/" + quote(index) + "/")
        except HTTPError:
            bailout("Unable to remove the entry " + index + "from list " + listname)

    def update_list_entry(self, listname, index, contents):
        ec = urllib.urlencode(contents)
        try:
            urllib2.urlopen(base + "/update/" + listname + "/" + str(index) + "/", ec)
        except HTTPError:
            bailout("Unable to update the list entry")
        
    def glob_listname(self, pattern):
        
        def match_listname(l):
            # This function doesn't seem very pythonic...
            if len(l) > 1:
                print str(len(l)) + " lists satifisfy the pattern : "
                print l

                try:
                    pat = raw_input("Enter a matching pattern to clarify your choice : ")
                except EOFError:
                    sys.exit(-1)

                return match_listname(fnmatch.filter(l, pat))
            else:
                return l[0]

        try:
            lists = self.get_lists_list()
            res = fnmatch.filter(lists, pattern)

            if len(res) > 1:
                return match_listname(res)
            else:
                return res[0]

        except HTTPError:
            bailout("Unable to glob list pattern")

def process_json_delayed_file(path):
    try:
        fd = open(path)
    except IOError:
        return

    data = json.load(fd)

    if "request" not in data or "listname" not in data:
        return # Discard incorrect files

    if data["request"] == "create-list":
        session.create_list(data["listname"])
    elif data["request"] == "create-entry":
        try:
            session.create_list_entry(data["listname"], data["content"]["title"]) 	# FIXME : use the other options if defined.
        except KeyError:
            return

    elif data["request"] == "delete-list":
        session.remove_list(data["listname"])
    elif data["request"] == "delete-entry":
        try:
            session.remove_list_entry(data["listname"], data["content"]["index"])
        except KeyError:
            return
    elif data["request"] == "update-entry":
        try:
            session.update_entry(data["listname"], data["content"]["index"], data["content"])
        except KeyError:
            return
        
    os.unlink(path)

def watch_spool_dir():
    while True:
        for file in os.listdir(os.path.expanduser('~/.liszt/delayed/')):
            process_json_delayed_file(os.path.expanduser('~/.liszt/delayed/') + file)
        
        time.sleep(15 * 60) # Sync the files with the server every 15 minutes.

def cache_new_lists():
    # This thread caches lists that were recently created on the server but are not available
    # on the client.

    server_set = set(session.get_lists_list())
    cached_set = set(os.listdir(os.path.expanduser('~/.liszt/cached/')))
    
    for list in server_set.difference(cached_set):
        try:
            fd = open(os.path.expanduser('~/.liszt/cached/') + list, 'w+')
        except IOError:
            continue

        dict = session.get_list(list)
        json.dump(dict, fd)
        fd.close()

    # Also save a list of the lists :
    fd = open(os.path.expanduser('~/.liszt/cached/lists_list'), 'w+')
    json.dump(session.get_lists_list(), fd)
    fd.close()

    time.sleep(15 * 60)
        
def sync_cached_list(path):
    def isentrydefined(title, list):
        # Is an entry in a list ? Yes if it's title is in the list
        for e in list:
            if e["title"] == title:
                return True

        return False

    try:
        fd = open(path)
    except IOError:
        return

    cached_list = json.load(fd)
    try:
        listname = cached_list["name"]
    except KeyError:
        return

    server_list = session.get_list(listname)

    for entry in server_list:
        if isinstance(entry, list): # Discard lists for the moment
            continue
        
        cached_list[entry] = server_list[entry]

    for entry in server_list["contents"]:
        if not isentrydefined(entry["title"], cached_list["contents"]):
            cached_list["contents"].push(entry)

    json.dump(fd)
    
def watch_cache_dir(name, session):
    while True:
        for file in os.listdir(os.path.expanduser('~/.liszt/cached/')):
            sync_cached_list(os.path.expanduser('~/.liszt/cached/') + file)
        
        time.sleep(20 * 60) # Sync the files with the server every 20 minutes.
    
if __name__ == "__main__":

    session = LisztSession()
    session.login(username, password)

    thread.start_new_thread(watch_spool_dir, ())
    thread.start_new_thread(cache_new_lists, ())

    while 1:pass
